{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset\n",
        "x_train, x_test, y_train, y_test = np.load('regression_data.npy', allow_pickle=True)\n",
        "\n",
        "# Reshape targets\n",
        "y_train = y_train.reshape(-1,)\n",
        "y_test = y_test.reshape(-1,)\n",
        "\n",
        "# Add bias term (column of ones)\n",
        "train_data = np.hstack((x_train, np.ones((x_train.shape[0], 1))))\n",
        "test_data = np.hstack((x_test, np.ones((x_test.shape[0], 1))))\n",
        "\n",
        "# ==============================\n",
        "# Task 1: Standard Linear Regression (Gradient Descent)\n",
        "# ==============================\n",
        "def linear_regression_train(x_train, y_train, lr=1e-3, iterations=7000):\n",
        "    weight = np.random.randn(2)\n",
        "    loss = np.zeros(iterations)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        y_pred = None  # Compute predicted values\n",
        "\n",
        "        loss[i] = None  # Compute MSE\n",
        "\n",
        "        # Compute gradients\n",
        "        m_gradient = None  # Compute gradient for weight\n",
        "        b_gradient = None  # Compute gradient for bias\n",
        "\n",
        "        # Update weights\n",
        "        weight[0] -= None  # Apply gradient descent for weight\n",
        "        weight[1] -= None  # Apply gradient descent for bias\n",
        "\n",
        "    return weight, loss\n",
        "\n",
        "weight_standard, loss_standard = linear_regression_train(train_data, y_train)\n",
        "\n",
        "print(\"\\n=== Standard Linear Regression Parameters ===\")\n",
        "print(f'Weight (m): {None}')  # Print weight[0]\n",
        "print(f'Bias (b): {None}')  # Print weight[1]\n",
        "\n",
        "# ==============================\n",
        "# Task 2: Compute MSE\n",
        "# ==============================\n",
        "def compute_mse(y_true, y_pred):\n",
        "    return None  # Compute MSE formula\n",
        "\n",
        "y_pred_standard = None  # Compute predictions for test data\n",
        "mse_standard = compute_mse(y_test, y_pred_standard)\n",
        "\n",
        "print(\"\\n=== Mean Squared Error (Standard Regression) ===\")\n",
        "print(f'MSE: {None}')\n",
        "\n",
        "# ==============================\n",
        "# Task 3: Ridge Regression (Gradient Descent)\n",
        "# ==============================\n",
        "def ridge_regression_train(x_train, y_train, lr=1e-3, iterations=7000, lambda_reg=0.1):\n",
        "    weight = np.random.randn(2)\n",
        "    loss = np.zeros(iterations)\n",
        "\n",
        "    for i in range(iterations):\n",
        "        y_pred = None  # Compute predicted values\n",
        "\n",
        "        loss[i] = None  # Compute MSE with regularization term\n",
        "\n",
        "        # Compute gradients with regularization\n",
        "        m_gradient = None  # Compute weight gradient with regularization\n",
        "        b_gradient = None  # Compute bias gradient\n",
        "\n",
        "        # Update weights\n",
        "        weight[0] -= None  # Apply gradient descent for weight\n",
        "        weight[1] -= None  # Apply gradient descent for bias\n",
        "\n",
        "    return weight, loss\n",
        "\n",
        "weight_ridge, loss_ridge = ridge_regression_train(train_data, y_train)\n",
        "\n",
        "print(\"\\n=== Ridge Regression Parameters ===\")\n",
        "print(f'Weight (m): {None}')\n",
        "print(f'Bias (b): {None}')\n",
        "\n",
        "y_pred_ridge = None  # Compute predictions for test data\n",
        "mse_ridge = compute_mse(y_test, y_pred_ridge)\n",
        "\n",
        "print(\"\\n=== Mean Squared Error (Ridge Regression) ===\")\n",
        "print(f'MSE: {None}')\n",
        "\n",
        "# ==============================\n",
        "# Task 4: Plot Loss Curve\n",
        "# ==============================\n",
        "\n",
        "# ==============================\n",
        "# Task 5: Closed-form Ridge Regression\n",
        "# ==============================\n",
        "def closed_form_ridge(x_train, y_train, lambda_reg=0.1):\n",
        "    I = np.eye(x_train.shape[1])\n",
        "    w_closed_form = None  # Compute closed-form solution (Equation 4.27)\n",
        "    return w_closed_form\n",
        "\n",
        "weight_closed_form = closed_form_ridge(train_data, y_train)\n",
        "y_pred_closed_form = None  # Compute predictions for test data\n",
        "mse_closed_form = compute_mse(y_test, y_pred_closed_form)\n",
        "\n",
        "print(\"\\n=== Closed-form Ridge Regression Parameters ===\")\n",
        "print(f'Weight (m): {None}')\n",
        "print(f'Bias (b): {None}')\n",
        "print(\"\\n=== Mean Squared Error (Closed-form Ridge Regression) ===\")\n",
        "print(f'MSE: {None}')\n",
        "\n",
        "# ==============================\n",
        "# Task 6: Predictive Distribution\n",
        "# ==============================\n",
        "predictive_mean = None  # Compute predictive mean\n",
        "predictive_variance = None  # Compute predictive variance\n",
        "\n",
        "print(\"\\n=== Predictive Distribution ===\")\n",
        "print(f'Predictive Mean (first 5 values): {None}')\n",
        "print(f'Predictive Variance: {None}')\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Task 7: Plot Predictions\n",
        "# ==============================\n",
        "\n",
        "\n",
        "# ==============================\n",
        "# Plot Confidence Intervals\n",
        "# ==============================\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 367
        },
        "id": "whiNSBZ0num-",
        "outputId": "c88aa1a1-b9ff-440b-a8ba-7351cc0c3705"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for -: 'float' and 'NoneType'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-87f3179cccc0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mweight_standard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_standard\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_regression_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== Standard Linear Regression Parameters ===\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-87f3179cccc0>\u001b[0m in \u001b[0;36mlinear_regression_train\u001b[0;34m(x_train, y_train, lr, iterations)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Apply gradient descent for weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# Apply gradient descent for bias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'NoneType'"
          ]
        }
      ]
    }
  ]
}
